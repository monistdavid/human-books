Question
===============

1. when is GPU needed and when is CPU needed?
    1. GPU is needed for training, is it needed for inference as well? (GPT Pretrained language model?)
    2. when the thread is generated and used to process the program. Can GPU be used in parallel processing? If not, why
       CPU can be used in parallel processing?
    3. talks about the NLP Cloud, how they work
2. If you were me, how would you start to do this project?
3. GPT is really versatile. If I Finetune GPT-J model with custom data, how much will I decrease its versatility? In
   other word, will it only reply response with what the custom data has? Or it still retains the knowledge from the GPT
   LM? What makes things different with fine-tuning blenderbot with GPT LM?
4. How serious will the uppercase lowercase influence the model
5. things to pay attention when doing finetune.
6. Cost for production or deployment
7. what account good data processing, what kind of data is well processed
8. what do you think of prompt based learning.

Notes
===============

1. GPU could definitely run model quicker, however, it cost a lot more to rent GPU RAM than CPU RAM.
    1. so larger model with low inference time should be used on CPU, smaller model with high inference time should be
       used on GPU. As this could balance the inference time of the program.
2. what to pay attention for Fine-tune in case that to fine-tune dataset is a lot different from the pretrained
   dataset.
    1. learning rate needs to be smaller than e-5
    2. input/output format needs to be the same as the pretrained model. (not only the format, but maybe the length
       of the data, the maximum number of turns in the dialogue dataset.)
    3. learning step/epoch, needs to be careful about model's quickly over-fitting
3. feedback system
   1. the ability to quickly update
4. 

Thoughts
===============

