Question
===============
1. when is GPU needed and when is CPU needed? 
   1. GPU is needed for training, is it needed for inference as well? (GPT Pretrained language model?)
   2. when the thread is generated and used to process the program. Can GPU be used in parallel processing?
      If not, why CPU can be used in parallel processing?
   3. talks about the NLP Cloud, how they work
2. If you were me, how would you start to do this project?
3. GPT is really versatile. If I Finetune GPT-J model with custom data, how much will I decrease its 
   versatility? In other word, will it only reply response with what the custom data has? Or it still
   retains the knowledge from the GPT LM? What makes things different with fine-tuning blenderbot with 
   GPT LM?
4. How serious will the uppercase lowercase influence the model
5. things to pay attention when doing finetune.
6. Cost for production or deployment
7. what account good data processing, what kind of data is well processed
8. what do you think of prompt based learning.

Notes
===============



Thoughts
===============


Summary
================